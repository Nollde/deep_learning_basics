{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1401ffeb",
   "metadata": {},
   "source": [
    "# Checkerboard Task - Regression\n",
    "In this exercise we will solve the checkerboard task using a regression approach.\n",
    "\n",
    "## Introduction\n",
    "The the data consists of 2D vectors (x1, x2) uniformly sampled in the range (-1, 1).\n",
    "The data samples are classified by the XOR (exclusive or) operation.\n",
    "\n",
    "The task is to train a simple neural network to correctly classify the data.\n",
    "For now we formulate this problem as regression task with the network predicting a single value y_model and the optimizer minimizing the mean squared error between model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac1e6d",
   "metadata": {},
   "source": [
    "## Imports and Seeding\n",
    "First we will do the necessary imports:\n",
    "* `numpy` for general data handling and array manipulation\n",
    "* `tensorflow` to build and train the regression model\n",
    "* `matplotlib.pyplot` for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e44804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d7138",
   "metadata": {},
   "source": [
    "Then we set a random seed for the `np.random` module. This makes our code reproducible as the random operations will yield the same results in every run through the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681e7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c76d5",
   "metadata": {},
   "source": [
    "## Data creation\n",
    "The the data consists of 2D vectors $(x_1, x_2)$ uniformly sampled in the range $(-1, 1)$.\n",
    "\n",
    "The data samples are classified as signal $y = 1$ if either $x_1>0$ or $x_2>0$ (but not both).\n",
    "\n",
    "* x = $(x_1, x_2)$ with random numbers $x_1, x_2$ ~ Uniform(-1, 1)\n",
    "* y = XOR$(x_1, x_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c1faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "xdata = np.random.uniform(low=-1, high=1, size=(N, 2)) # shape = (N, 2)\n",
    "ydata = (xdata[:, :1] * xdata[:, 1:]) < 0  # shape = (N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b17d4",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "We build a simple neural netowork.\n",
    "\n",
    "**TODO**: Inspect the implemented model. What is the total number of parameters? Do the calculation by pen&paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3f4fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 12:03:53.151970: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(4, activation=\"relu\", input_dim=2),\n",
    "        tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ba1bd",
   "metadata": {},
   "source": [
    "**TODO**: Now verify your pen&paper result using the `model.summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ea5b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO: Extract the number of parameters of your model.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: Extract the number of parameters of your model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263bc2d",
   "metadata": {},
   "source": [
    "Define objective, optimizer and prepare TF computation graph:\n",
    "* objective: mean squared error\n",
    "* optimizer: (stochastic) gradient descent\n",
    "* metrics: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff81b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-2\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate)\n",
    "model.compile(\n",
    "    loss=\"mse\",  \n",
    "    optimizer=sgd,  \n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34d6e6",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Now train the model to an accuracy of at least 90%. How many epochs are needed to this?\n",
    "\n",
    "**Hint:** The `verbose` argument sets the verbosity of shell output `(0: none, 1: high, 2: low)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0470cb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 12:07:24.923012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: How many epochs of training are needed to achieve an accuracy of 90%?\n",
    "\"\"\"\n",
    "n_epochs = 1\n",
    "fit = model.fit(\n",
    "    xdata,\n",
    "    ydata,\n",
    "    epochs=n_epochs,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7b6c2",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Now we want to visualize the predicitons of our model and the training data in the two dimensions ($x_1$ and $x_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d6e02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Evaluate the output of your model output depending on the two dimensions ($x_1$ and $x_2$).\n",
    "Visualize the output of your model along with the training data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eafe59",
   "metadata": {},
   "source": [
    "## Further Tasks\n",
    "Change the network according to the following configurations and retrain the model.\n",
    "- 8 neurons in the hidden layer\n",
    "- 2 neurons in the hidden layer\n",
    "- Add an additional hidden layer of 4 neurons with a ReLU activation\n",
    "\n",
    "Describe your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10210c5c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This concludes our tutorial on solving the checkerboard task using a regression\n",
    "\n",
    "In this tutorial you have learned:\n",
    "* How to build a non-linear tf.keras model\n",
    "* How to calculate the number of parameters of a neural network\n",
    "* How to train a tf.keras model on a given data distribution\n",
    "* How to visualize two dimensional data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
