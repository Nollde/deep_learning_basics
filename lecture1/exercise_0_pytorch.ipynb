{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3881ec5d",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial\n",
    "---------------\n",
    "Welcome to the pytorch tutorial! Here we will go through some of the basics of pytorch.\n",
    "\n",
    "The library can be imported the as ```torch```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e812c4c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/z8g0cw_s0nzcv0z1jn7vfgsm0000gn/T/ipykernel_1180/4265195184.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232eb87a",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Even if the name ```pytorch``` is not as telling as ```tensorflow```, ```pytorch``` supports the creation of tensors too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da356762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,   5.,   9.,  15., -24., -13.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1., 5., 9., 15., -24., -13.])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab59c06",
   "metadata": {},
   "source": [
    "These objects can both **store data and model parameters** (recall that in tensorflow ```tf.Variable``` is a child class of ```tf.Tensor``` and used for storing weights). To check whether a tensor is storing gradients, one can use the ```requires_grad``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e83bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a84d9",
   "metadata": {},
   "source": [
    "To initialize a **tensor with gradients** one can use the ```requires_grad``` keyword during initialization; this creates the rough equivalent of a ```tf.Variable```. To obtain the gradients, ```.backward()``` has to be called on the output object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6a9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor x_i:       tensor([  1.,   5.,   9.,  15., -24., -13.], requires_grad=True)\n",
      "Gradients of Σ_i x²_i:   tensor([  2.,  10.,  18.,  30., -48., -26.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with gradients and print it:\n",
    "tensor_grad = torch.tensor([1., 5., 9., 15., -24., -13.], requires_grad=True)\n",
    "print(\"Input tensor x_i:      \", tensor_grad)\n",
    "\n",
    "# Perform an operation on the tensor itself and sum the output making it a 1D function:\n",
    "output = (tensor_grad ** 2).sum()   # This defines y = Σ_i x²_i for every x_i\n",
    "# Evaluating the gradients:\n",
    "output.backward()\n",
    "# ...and printing 'em:\n",
    "print(\"Gradients of Σ_i x²_i:  \", tensor_grad.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e583095",
   "metadata": {},
   "source": [
    "**Conversion** from and to ```numpy``` is also supported in an intuitive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c285066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor created from a numpy array:  tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "An array created from a torch tensor: [0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tensor_from_np = torch.tensor(np.arange(10)).float()\n",
    "print(\"A tensor created from a numpy array: \", tensor_from_np)\n",
    "\n",
    "tensor_torch  = torch.linspace(0, 5, 6).float()\n",
    "array_from_torch = tensor_torch.numpy()\n",
    "print(\"An array created from a torch tensor:\", array_from_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3a5ce",
   "metadata": {},
   "source": [
    "## Fundamental Mathematical Operations\n",
    "```pytorch``` supports several basic mathematical operations on tensors too. Its syntax more or less follows that of ```numpy``` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9b99ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.5000)\n",
      "Std : tensor(3.0277)\n",
      "\n",
      "Normal Sample Properties:\n",
      "   Shape: torch.Size([1, 10000])\n",
      "   Mean:  tensor(0.9942)\n",
      "   Std:   tensor(0.5033)\n",
      "\n",
      "The first row of the normal samples:\n",
      "tensor([0.6045, 0.4586, 0.8431,  ..., 1.5992, 0.4570, 1.2081])\n"
     ]
    }
   ],
   "source": [
    "# A toy tensor:\n",
    "tensor = torch.arange(10).float()  # Create a tensor from 0 to 9\n",
    "print(\"Mean:\", torch.mean(tensor))\n",
    "print(\"Std :\", torch.std(tensor))\n",
    "\n",
    "# Random numbers:\n",
    "#  A normal sample with mean 1 and std 0.5:\n",
    "normal = torch.normal(mean=1., std=0.5, size=[1, 10000])\n",
    "print(\"\\nNormal Sample Properties:\")\n",
    "print(\"   Shape:\", normal.shape)\n",
    "print(\"   Mean: \", normal.mean())\n",
    "print(\"   Std:  \", normal.std())\n",
    "\n",
    "#  Getting elements along an axis (slicing):\n",
    "print(\"\\nThe first row of the normal samples:\")\n",
    "print(normal[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f283cd2",
   "metadata": {},
   "source": [
    " A key **difference in syntax** however is that ```pytorch``` knows the ```axis``` keyword as ```dim```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe72fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform Sample Properties:\n",
      "   Shape: torch.Size([3, 100000])\n",
      "   Mean:  tensor([0.5000, 0.4996, 0.5005])\n",
      "   Std:   tensor([0.2893, 0.2885, 0.2884])\n"
     ]
    }
   ],
   "source": [
    "#  A uniform sample from [0, 1)\n",
    "uniform = torch.rand([3, 100000])\n",
    "print(\"\\nUniform Sample Properties:\")\n",
    "print(\"   Shape:\", uniform.shape)\n",
    "print(\"   Mean: \", uniform.mean(dim=1))  # Equals 1/2 ≈ 0.5, the mean of a uniform distribution between [0, 1)\n",
    "print(\"   Std:  \", uniform.std(dim=1))   # Equals 1/12**0.5 ≈ 0.2887, the std of a uniform distribution of width 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01db24d",
   "metadata": {},
   "source": [
    "### Task <a class=\"tocSkip\">\n",
    "Implement the mean-square difference function in pytorch:\n",
    "$ L(x, y) = \\sum_i \\frac{(x_i-y_i)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d674de00",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3637020795.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(loss(x,y))?\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def loss(x, y):\n",
    "    # TODO: replace the return term\n",
    "    return 0.\n",
    "\n",
    "# Use these values of x and y to get the variation using L for a uniformly distributed dataset in [0, 1)\n",
    "x = torch.rand([1000000])\n",
    "y = torch.ones([1000000]) * 0.5\n",
    "\n",
    "# Result should be around 0.083333\n",
    "print(loss(x,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
