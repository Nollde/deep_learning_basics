{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3881ec5d",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial\n",
    "---------------\n",
    "Welcome to the pytorch tutorial! Here we will go through some of the basics of pytorch.\n",
    "\n",
    "The library can be imported the as ```torch```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e812c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232eb87a",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Even if name ```pytorch``` is not as telling as ```tensorflow```, ```pytorch``` supports the creation of tensors too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da356762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,   5.,   9.,  15., -24., -13.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1., 5., 9., 15., -24., -13.])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab59c06",
   "metadata": {},
   "source": [
    "These objects can both **store data and model parameters** (recall that in tensorflow ```tf.Variable``` is a child class of ```tf.Tensor``` and used for storing weights). To check whether a tensor is storing gradients, one can use the ```requires_grad``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e83bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a84d9",
   "metadata": {},
   "source": [
    "To initialize a **tensor with gradients** one can use the ```requires_grad``` keyword during initialization; this creates the rough equivalent of a ```tf.Variable```. To obtain the gradients, ```.backward()``` has to be called on the output object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d6a9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor xᵢ:       tensor([  1.,   5.,   9.,  15., -24., -13.], requires_grad=True)\n",
      "Gradients of Σᵢ xᵢ²:   tensor([  2.,  10.,  18.,  30., -48., -26.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with gradients and print it:\n",
    "tensor_grad = torch.tensor([1., 5., 9., 15., -24., -13.], requires_grad=True)\n",
    "print(\"Input tensor xᵢ:      \", tensor_grad)\n",
    "\n",
    "# Perform an operation on the tensor itself and sum the output making it a 1D function:\n",
    "output = (tensor_grad ** 2).sum()   # This defines y = Σᵢ xᵢ² for every xᵢ\n",
    "# Evaluating the gradients:\n",
    "output.backward()\n",
    "# ...and printing 'em:\n",
    "print(\"Gradients of Σᵢ xᵢ²:  \", tensor_grad.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546969ea",
   "metadata": {},
   "source": [
    "**Conversion** from and to ```numpy``` is also supported in an intuitive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b15a0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor created from a numpy array:  tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "An array created from a torch tensor: [0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tensor_from_np = torch.tensor(np.arange(10)).float()\n",
    "print(\"A tensor created from a numpy array: \", tensor_from_np)\n",
    "\n",
    "tensor_torch  = torch.linspace(0, 5, 6).float()\n",
    "array_from_torch = tensor_torch.numpy()\n",
    "print(\"An array created from a torch tensor:\", array_from_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3a5ce",
   "metadata": {},
   "source": [
    "## Fundamental Mathematical Operations\n",
    "```pytorch``` supports several basic mathematical operations on tensors too. Its syntax more or less follows that of ```numpy``` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b164940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.5000)\n",
      "Std : tensor(3.0277)\n",
      "\n",
      "Normal Sample Properties:\n",
      "   Shape: torch.Size([1, 10000])\n",
      "   Mean:  tensor(1.0189)\n",
      "   Std:   tensor(0.4937)\n",
      "\n",
      "The first row of the normal samples:\n",
      "tensor([1.1931, 0.7112, 1.0409,  ..., 1.2609, 0.1830, 1.6109])\n"
     ]
    }
   ],
   "source": [
    "# A toy tensor:\n",
    "tensor = torch.arange(10).float()  # Create a tensor from 0 to 9\n",
    "print(\"Mean:\", torch.mean(tensor))\n",
    "print(\"Std :\", torch.std(tensor))\n",
    "\n",
    "# Random numbers:\n",
    "#  A normal sample with mean 1 and std 0.5:\n",
    "normal = torch.normal(mean=1., std=0.5, size=[1, 10000])\n",
    "print(\"\\nNormal Sample Properties:\")\n",
    "print(\"   Shape:\", normal.shape)\n",
    "print(\"   Mean: \", normal.mean())\n",
    "print(\"   Std:  \", normal.std())\n",
    "\n",
    "#  Getting elements along an axis (slicing):\n",
    "print(\"\\nThe first row of the normal samples:\")\n",
    "print(normal[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046ab07",
   "metadata": {},
   "source": [
    " A key **difference in syntax** however is that ```pytorch``` knows the ```axis``` keyword as ```dim```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d244cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform Sample Properties:\n",
      "   Shape: torch.Size([3, 100000])\n",
      "   Mean:  tensor([0.4991, 0.5005, 0.4996])\n",
      "   Std:   tensor([0.2888, 0.2885, 0.2884])\n"
     ]
    }
   ],
   "source": [
    "#  A uniform sample from [0, 1)\n",
    "uniform = torch.rand([3, 100000])\n",
    "print(\"\\nUniform Sample Properties:\")\n",
    "print(\"   Shape:\", uniform.shape)\n",
    "print(\"   Mean: \", uniform.mean(dim=1))  # Equals 1/2 ≈ 0.5, the mean of a uniform distribution between [0, 1)\n",
    "print(\"   Std:  \", uniform.std(dim=1))   # Equals 1/12**0.5 ≈ 0.2887, the std of a uniform distribution of width 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
